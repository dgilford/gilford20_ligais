{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we develop and save out the emulator for the last interglacial period. The saved emulator will be sampled (in **sample_lig_emulator.ipynb**) to constrain the parameter values that are then used to sample from the RCP8.5 scenario emulator to inform future projections of sea level rise.\n",
    "\n",
    "The steps in this code are:\n",
    "\n",
    "    1. Load in the LIG simulations\n",
    "    2. Structure the Data for Emulation\n",
    "        a. Normalize the axes\n",
    "        b. Create a parameter grid mesh\n",
    "    3. Define the emulator covariance and Train/condition on the data\n",
    "    4. Visualize the Model Mean and Variance\n",
    "    5. Save the emulator\n",
    "    \n",
    "We note that the structure of this emulator was chosen in **lig_cv_validation.ipynb** comparing different choices of CV functions. In this code, the structure is assumed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# import the relevant packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define colormap\n",
    "plt.set_cmap('viridis')\n",
    "from lig_utilities import draw_straight_line\n",
    "# define the save path for our plots\n",
    "save_path='./figures/'\n",
    "# set the default grid style\n",
    "plt.rcParams['grid.color'] = 'k'\n",
    "plt.rcParams['grid.linestyle'] = ':'\n",
    "plt.rcParams['grid.linewidth'] = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the GPflow package for GP regression\n",
    "import gpflow\n",
    "from lig_utilities import normalize, denormalize, archive_gpflow_model\n",
    "from datetime import datetime\n",
    "# import tensorflow so we can save the trained model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data location\n",
    "lig_path='./data/lig_data_dec18.pk1'\n",
    "# load dictionary containing the data\n",
    "lig_data=pickle.load( open( lig_path, \"rb\" ) )\n",
    "# define parameter value grids\n",
    "crevliq=lig_data['crevliq']\n",
    "clifvmax=lig_data['clifvmax']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LIG simulations are intended to be equilibrium runs in response to fixed forcing, and are therefore best to be compared with LIG estimates (and hence for emulation) at their final time point. We extract the data at the final time point to train the emulator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# What does this data at the final time point look like? Refer to \"plot_original_sims.ipynb\"\n",
    "lig_data['tais'].tail(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the target data at the final time point (the training target points):\n",
    "ligY_train=np.asarray(lig_data['tais'].tail(1),dtype='float64')\n",
    "ligY=np.asarray(ligY_train,dtype='float64').reshape(len(clifvmax),len(crevliq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize LIG Simulated Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the histogram of the ensemble at 125ka compared with the Dutton et al. (2015/D20) bounds of [3.1-6.1 meters] at maximum AIS retreat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig_dist_fig=plt.figure()\n",
    "plt.grid()\n",
    "plt.hist(np.squeeze(ligY_train),bins=np.linspace(2,7,11),normed=True)\n",
    "plt.xlabel('LIG: AIS Sea Level Contributions (m)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Probability Distribution of AIS SL contributions during the LIG')\n",
    "# plot the Dutton et al. (2015) bounds\n",
    "plt.plot([3.1,3.1],[0,0.5],'r--',lw=2)\n",
    "plt.plot([6.1,6.1],[0,0.5],'r--',lw=2)\n",
    "plt.xlim([2.49,7.01])\n",
    "plt.ylim([0,0.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure the Data for Emulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the length scales of the axes\n",
    "CLIFVMAX_norm=normalize(clifvmax)\n",
    "CREVLIQ_norm=normalize(crevliq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a meshgrid of the defined parameters and time, and then reshape\n",
    "xv, yv= np.meshgrid(CLIFVMAX_norm, CREVLIQ_norm, indexing='ij')\n",
    "nx,ny = len(clifvmax),len(crevliq)\n",
    "\n",
    "# build the grid on which the data lies for emulation\n",
    "X_train=np.transpose([yv,xv]).reshape(nx*ny,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform the emulation we use [GPflow](https://gpflow.readthedocs.io/en/develop/index.html), a Python package that utilizes tensorflow for computational efficiency. GPflow has the distinct advantage that out-of-the-box it permits defining components of the covariance structure along \"active dimensions\", specifically allowing the structure to be anisotopic if the user wants that behavior. Furthermore, GPflow assumes a prior mean function of 0, and then iterates in its optimization toward a mean structure consistent with the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a sample grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a grid of parameter values which we can sample from to visualize our results. Note that because our training axes have been normalized, our samples are also drawn from a uniform distribution between 0 and 1, and then denormalized for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid for visualization\n",
    "sample_crevliq=np.linspace(-0.1,1.1,70)\n",
    "sample_clifvmax=np.linspace(-0.1,1.1,70)\n",
    "xx, yy = np.meshgrid(sample_clifvmax,sample_crevliq, indexing='ij')\n",
    "ns1,ns2 = len(sample_clifvmax),len(sample_crevliq)\n",
    "X_sample=np.transpose([yy,xx]).reshape(ns1*ns2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# denormalize the sample grid\n",
    "denorm_x=denormalize(sample_clifvmax,np.max(clifvmax),np.min(clifvmax))\n",
    "denorm_y=denormalize(sample_crevliq,np.max(crevliq),np.min(crevliq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Emulator: k = Matern 1/2(CLIFVMAX,CREVLIQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model name\n",
    "model_name='lig_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an object to time the emulation\n",
    "startTime = datetime.now()\n",
    "\n",
    "# create the GP model\n",
    "with gpflow.defer_build():\n",
    "    \n",
    "    # define a kernel and store the code for reconstruction\n",
    "    k=gpflow.kernels.Matern12(2,active_dims=[0,1])\n",
    "    kernel_code='gpflow.kernels.Matern12(2,active_dims=[0,1])'\n",
    "    \n",
    "    # create the model\n",
    "    m = gpflow.models.GPR(X_train, ligY_train.reshape(np.size(ligY_train),1), kern=k, name=model_name)\n",
    "\n",
    "# construct and compile the tensorflow session\n",
    "tf.global_variables_initializer()\n",
    "tf_session = m.enquire_session()\n",
    "m.compile( tf_session )\n",
    "\n",
    "#train the model\n",
    "opt = gpflow.train.ScipyOptimizer()\n",
    "opt.minimize(m)\n",
    "\n",
    "# print the elapse time for the emulation\n",
    "print(datetime.now() - startTime)\n",
    "\n",
    "# archive the model (uncomment for archiving model runs)\n",
    "# archive_gpflow_model(m,kernel_code,tf_session,save_dir='./archived_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the noise term\n",
    "m.likelihood.variance = 1e-06"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set the point-wise kernel variance (i.e. the nugget) to a very small number. The model log-likelihood is give by the \"Objective function value\" above.\n",
    "\n",
    "Let's look at the table with the model properties and hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the relevant model parameters\n",
    "m.as_pandas_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Model Mean Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model outputs along grid\n",
    "gpr_mean,gpr_var=m.predict_y(X_sample)\n",
    "\n",
    "# denormalize the training grid\n",
    "denorm_points_x=denormalize(X_train[:,1],np.max(clifvmax),np.min(clifvmax))\n",
    "denorm_points_y=denormalize(X_train[:,0],np.max(crevliq),np.min(crevliq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose the levels for the plot\n",
    "min_val,max_val=3.0,6.5\n",
    "clevels=np.linspace(min_val,max_val,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot the sample\n",
    "gp_mean_fig=plt.figure()\n",
    "c1=plt.contourf(denorm_x,denorm_y,gpr_mean.reshape(ns1,ns2),clevels)\n",
    "c2=plt.scatter(denorm_points_x,denorm_points_y,c=np.squeeze(ligY_train),s=100,norm=c1.norm,edgecolors='k')\n",
    "plt.xlabel('CLIFVMAX (km/yr)')\n",
    "plt.ylabel('CREVLIQ (m per (m yr$^{−1}$)$^{2}$)')\n",
    "plt.title('LIG AIS Contributions to SL (m), Emulator and Simulations')\n",
    "plt.ylim([-2.5,197.5])\n",
    "plt.xlim([-0.2,13.2])\n",
    "plt.xticks(clifvmax)\n",
    "plt.yticks(crevliq)\n",
    "plt.colorbar(c1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plot out\n",
    "savename='Fig2a.pdf'\n",
    "gp_mean_fig.savefig(save_path+savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the Variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the levels for the plot\n",
    "min_val,max_val=0,0.02\n",
    "np.max(gpr_var.reshape(ns1,ns2))\n",
    "clevels=np.linspace(min_val,max_val,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean(gpr_var.reshape(ns1,ns2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for the square euclidean distance\n",
    "gp_var_fig=plt.figure()\n",
    "c1=plt.contourf(denorm_x,denorm_y,gpr_var.reshape(ns1,ns2),clevels)\n",
    "plt.xlabel('CLIFVMAX (km/yr)')\n",
    "plt.ylabel('CREVLIQ (m per (m yr$^{−1}$)$^{2}$)')\n",
    "plt.title('LIG AIS Contributions to SL (m) Emulator and Simulations')\n",
    "plt.title('LIG Emulator Variance (m$^2$)')\n",
    "plt.ylim([-2.5,197.5])\n",
    "plt.xlim([-0.2,13.2])\n",
    "plt.xticks(clifvmax)\n",
    "plt.yticks(crevliq)\n",
    "plt.colorbar(c1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the plot out\n",
    "savename='FigS7.pdf'\n",
    "gp_var_fig.savefig(save_path+savename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model object is a tensorflow object, so we utilize tensorflow's built in saving method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the saver object and archive the model object\n",
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(tf_session, \"./models/lig_model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Data to reconstruct the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reconstruct the model in **sample_lig_emulator.ipynb**, it is helpful to save out the training data which has already been conditioned in this code for emulation. This saves us multiple steps in the sampling code, and ensures we are using the identical data structure to restore the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the training data\n",
    "train_dat={'X_train': X_train, 'Y_train': ligY_train, 'crevliq':crevliq, 'clifvmax': clifvmax, \\\n",
    "          'model_name': model_name, 'kernel_code': kernel_code}\n",
    "\n",
    "# save the training data\n",
    "pickle.dump(train_dat, open( \"./models/lig_model_traindata.pk1\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
